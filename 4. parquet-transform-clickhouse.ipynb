{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59d9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, udf\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, IntegerType\n",
    "\n",
    "# Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RedditKafkaConsumer\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9005a1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+-------------+-----+-----------------+--------------------+--------------------+---------------+\n",
      "|     id|                body|            author|  created_utc|score|        subreddit|           permalink|     sentiment_score|sentiment_label|\n",
      "+-------+--------------------+------------------+-------------+-----+-----------------+--------------------+--------------------+---------------+\n",
      "|mzc4d1m|        Donald Trump| Ok-Importance8753|1.750689657E9|    1|        AskReddit|/r/AskReddit/comm...|                 0.0|        neutral|\n",
      "|mzc4ed3|It's important to...|         Shapen361|1.750689667E9|    1|           stocks|/r/stocks/comment...|0.016888888888888873|        neutral|\n",
      "|mzc4lqq|Of course they sh...|      changelingcd|1.750689727E9|    1|           canada|/r/canada/comment...|-0.19270833333333331|       negative|\n",
      "|mzc4meg|> Shaping the Con...|        HaLoGuY007|1.750689732E9|    1|    foreignpolicy|/r/foreignpolicy/...| 0.05886952861952861|        neutral|\n",
      "|mzc4ozi|Eric S. Swider is...|        Diofaduk00|1.750689753E9|    1|   wallstreetbets|/r/wallstreetbets...|                 0.0|        neutral|\n",
      "|mzc4prc|Epstein is quoted...|         RunShorty|1.750689759E9|    1|   NoShitSherlock|/r/NoShitSherlock...|                -0.1|        neutral|\n",
      "|mzc4rmk|Trump wanted to d...|AcanthisittaNo6653|1.750689775E9|    1|InternationalNews|/r/InternationalN...|                 0.6|       positive|\n",
      "|mzc4vlr|If you think this...|      floweryroads|1.750689808E9|    1|           canada|/r/canada/comment...|                 0.2|       positive|\n",
      "|mzc4wwx|High risk, high r...|       airforceCOT|1.750689819E9|    1| moderatepolitics|/r/moderatepoliti...|                0.17|       positive|\n",
      "|mzc4y8g|Dems don't need t...|        pablonieve|1.750689829E9|    1|  fivethirtyeight|/r/fivethirtyeigh...| 0.35000000000000003|       positive|\n",
      "+-------+--------------------+------------------+-------------+-----+-----------------+--------------------+--------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/home/jovyan/stream-output/parquet/*\")  # Using wildcard to skip metadata folder\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75921855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+---------------+-----+--------------+\n",
      "|     id|        subreddit|sentiment_label|score|comment_length|\n",
      "+-------+-----------------+---------------+-----+--------------+\n",
      "|mzc4d1m|        AskReddit|        neutral|    1|            12|\n",
      "|mzc4ed3|           stocks|        neutral|    1|           869|\n",
      "|mzc4lqq|           canada|       negative|    1|           913|\n",
      "|mzc4meg|    foreignpolicy|        neutral|    1|          6351|\n",
      "|mzc4ozi|   wallstreetbets|        neutral|    1|           386|\n",
      "|mzc4prc|   NoShitSherlock|        neutral|    1|           132|\n",
      "|mzc4rmk|InternationalNews|       positive|    1|           250|\n",
      "|mzc4vlr|           canada|       positive|    1|            96|\n",
      "|mzc4wwx| moderatepolitics|       positive|    1|           363|\n",
      "|mzc4y8g|  fivethirtyeight|       positive|    1|           439|\n",
      "+-------+-----------------+---------------+-----+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    from_unixtime, to_date, hour, dayofweek, length, col\n",
    ")\n",
    "\n",
    "# Load data\n",
    "df = spark.read.parquet(\"/home/jovyan/stream-output/parquet/*\")\n",
    "\n",
    "# Basic cleaning\n",
    "df_clean = df.dropna(subset=[\"body\", \"author\", \"created_utc\", \"sentiment_label\"])\n",
    "\n",
    "# Feature engineering\n",
    "df_transformed = df_clean \\\n",
    "    .withColumn(\"created_datetime\", from_unixtime(\"created_utc\")) \\\n",
    "    .withColumn(\"date\", to_date(col(\"created_datetime\"))) \\\n",
    "    .withColumn(\"hour\", hour(col(\"created_datetime\"))) \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(col(\"created_datetime\"))) \\\n",
    "    .withColumn(\"comment_length\", length(col(\"body\"))) \\\n",
    "    .withColumn(\"sentiment_label\", col(\"sentiment_label\").cast(\"string\")) \\\n",
    "    .withColumn(\"score\", col(\"score\").cast(\"int\"))\n",
    "\n",
    "# Optionally cache if doing exploration\n",
    "df_transformed.cache()\n",
    "\n",
    "# Show preview\n",
    "df_transformed.select(\"id\", \"subreddit\", \"sentiment_label\", \"score\", \"comment_length\").show(10)\n",
    "\n",
    "# Save as new Parquet or database table\n",
    "df_transformed.write.mode(\"overwrite\").parquet(\"/home/jovyan/cleaned/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01f938b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x7fb721f85b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to Pandas\n",
    "df_pandas = df_transformed.toPandas()\n",
    "\n",
    "# Use clickhouse-connect (pip install clickhouse-connect)\n",
    "import clickhouse_connect\n",
    "\n",
    "client = clickhouse_connect.get_client(host='clickhouse-server', port=8123, username='default', password='1234')\n",
    "\n",
    "client.command(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS reddit_cleaned (\n",
    "    id String,\n",
    "    body String,\n",
    "    author String,\n",
    "    created_utc UInt32,\n",
    "    score Int32,\n",
    "    subreddit String,\n",
    "    permalink String,\n",
    "    sentiment_score Float32,\n",
    "    sentiment_label String,\n",
    "    created_datetime DateTime,\n",
    "    date Date,\n",
    "    hour UInt8,\n",
    "    day_of_week UInt8,\n",
    "    comment_length UInt16\n",
    ") ENGINE = MergeTree()\n",
    "ORDER BY (date, subreddit)\n",
    "\"\"\")\n",
    "\n",
    "# Convert the 'created_datetime' column to datetime type if it's not already\n",
    "df_pandas['created_datetime'] = pd.to_datetime(df_pandas['created_datetime'])\n",
    "\n",
    "client.insert_df(\"reddit_cleaned\", df_pandas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123f30f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               body  \\\n",
      "0  mzc6cbx  I donâ€˜t know how smart it is to ask Trump for ...   \n",
      "1  mzc6e7t  Trump doesn't want a full scale war. There's a...   \n",
      "2  mzc8mno  So what they are just pull everything out of t...   \n",
      "3  mzcjyy7  They aren't silent but MSM is not amplifying a...   \n",
      "4  mzcka7d    Wow, he sound so similar to Trump when speaking   \n",
      "\n",
      "                 author  created_utc  score         subreddit  \\\n",
      "0          ReadyLab5110   1750690236      1  2westerneurope4u   \n",
      "1        HereIGoAgain99   1750690252      1  2westerneurope4u   \n",
      "2              Sciomnia   1750690901      1  2westerneurope4u   \n",
      "3  Equivalent_Nerve_870   1750694125      1             50501   \n",
      "4         Low-Slide4516   1750694211      1               70s   \n",
      "\n",
      "                                           permalink  sentiment_score  \\\n",
      "0  /r/2westerneurope4u/comments/1liierd/germany_m...         0.357143   \n",
      "1  /r/2westerneurope4u/comments/1ligwhe/its_time/...         0.175000   \n",
      "2  /r/2westerneurope4u/comments/1lihe0w/but_why_d...        -0.060000   \n",
      "3  /r/50501/comments/1lih3eg/why_arent_more_famou...         0.000000   \n",
      "4  /r/70s/comments/1lhtmrl/the_last_time_we_had_r...         0.166667   \n",
      "\n",
      "  sentiment_label    created_datetime       date  hour  day_of_week  \\\n",
      "0        positive 2025-06-23 14:50:36 2025-06-23    14            2   \n",
      "1        positive 2025-06-23 14:50:52 2025-06-23    14            2   \n",
      "2         neutral 2025-06-23 15:01:41 2025-06-23    15            2   \n",
      "3         neutral 2025-06-23 15:55:25 2025-06-23    15            2   \n",
      "4        positive 2025-06-23 15:56:51 2025-06-23    15            2   \n",
      "\n",
      "   comment_length  \n",
      "0              98  \n",
      "1              62  \n",
      "2             408  \n",
      "3              98  \n",
      "4              47  \n"
     ]
    }
   ],
   "source": [
    "df = client.query_df('SELECT * FROM reddit_cleaned LIMIT 10')\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
